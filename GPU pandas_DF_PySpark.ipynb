{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sba22223nestorpereira/PySpark/blob/main/GPU%20pandas_DF_PySpark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23464bc7",
      "metadata": {
        "id": "23464bc7",
        "outputId": "c078ee49-37a9-43d4-ddc6-721e3ca46962"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Scott</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Jeff</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Thomas</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ann</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Name  Age\n",
              "0   Scott   50\n",
              "1    Jeff   45\n",
              "2  Thomas   54\n",
              "3     Ann   34"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "author SparkByExamples.com\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd    \n",
        "data = [['Scott', 50], ['Jeff', 45], ['Thomas', 54],['Ann',34]] \n",
        "  \n",
        "# Create the pandas DataFrame \n",
        "pandasDF = pd.DataFrame(data, columns = ['Name', 'Age']) \n",
        "  \n",
        "# print dataframe. \n",
        "pandasDF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af538646",
      "metadata": {
        "id": "af538646",
        "outputId": "adfd8de2-4b50-4407-acd9-1ae670f4c31d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: An illegal reflective access operation has occurred\n",
            "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/nestor/opt/anaconda3/envs/PySpark/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
            "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
            "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
            "WARNING: All illegal access operations will be denied in a future release\n",
            "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
            "23/01/19 18:04:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
            "23/01/19 18:04:26 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Age: long (nullable = true)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r",
            "[Stage 0:>                                                          (0 + 0) / 1]\r",
            "\r",
            "[Stage 0:>                                                          (0 + 1) / 1]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+---+\n",
            "|  Name|Age|\n",
            "+------+---+\n",
            "| Scott| 50|\n",
            "|  Jeff| 45|\n",
            "|Thomas| 54|\n",
            "|   Ann| 34|\n",
            "+------+---+\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r",
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .master(\"local[1]\") \\\n",
        "    .appName(\"SparkPandas\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "sparkDF=spark.createDataFrame(pandasDF) \n",
        "sparkDF.printSchema()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22d683c5",
      "metadata": {
        "id": "22d683c5",
        "outputId": "1ce5fcbf-c240-4cea-f123-aad3bd018527"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+---+\n",
            "|  Name|Age|\n",
            "+------+---+\n",
            "| Scott| 50|\n",
            "|  Jeff| 45|\n",
            "|Thomas| 54|\n",
            "|   Ann| 34|\n",
            "+------+---+\n",
            "\n",
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Age: long (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sparkDF.show()  # DF in PySpark\n",
        "sparkDF.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45a7a4b7",
      "metadata": {
        "id": "45a7a4b7",
        "outputId": "14fc144e-10fe-4ac2-a2a0-10856df1dcfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- First Name: string (nullable = true)\n",
            " |-- Age: integer (nullable = true)\n",
            "\n",
            "+----------+---+\n",
            "|First Name|Age|\n",
            "+----------+---+\n",
            "|     Scott| 50|\n",
            "|      Jeff| 45|\n",
            "|    Thomas| 54|\n",
            "|       Ann| 34|\n",
            "+----------+---+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#sparkDF=spark.createDataFrame(pandasDF.astype(str)) \n",
        "# from pandas\n",
        "\n",
        "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
        "\n",
        "mySchema = StructType([ StructField(\"First Name\", StringType(), True)\\\n",
        "                       ,StructField(\"Age\", IntegerType(), True)])\n",
        "\n",
        "sparkDF2 = spark.createDataFrame(pandasDF,schema=mySchema)\n",
        "sparkDF2.printSchema()\n",
        "sparkDF2.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c0488cc",
      "metadata": {
        "id": "2c0488cc",
        "outputId": "3426d74a-b937-4cef-e23b-e8d4f9c8df56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<bound method PandasConversionMixin.toPandas of DataFrame[First Name: string, Age: int]>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/01/19 18:09:15 WARN SQLConf: The SQL config 'spark.sql.execution.arrow.enabled' has been deprecated in Spark v3.0 and may be removed in the future. Use 'spark.sql.execution.arrow.pyspark.enabled' instead of it.\n"
          ]
        }
      ],
      "source": [
        "spark.conf.set(\"spark.sql.execution.arrow.enabled\",\"true\")\n",
        "spark.conf.set(\"spark.sql.execution.arrow.pyspark.fallback.enabled\",\"true\")\n",
        "\n",
        "pandasDF2 = sparkDF2.select(\"*\").toPandas\n",
        "\n",
        "print(pandasDF2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a1c5334",
      "metadata": {
        "id": "6a1c5334",
        "outputId": "beaeb429-23ab-4506-b2b2-347735677cf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "true\n",
            "true\n"
          ]
        }
      ],
      "source": [
        "\n",
        "test=spark.conf.get(\"spark.sql.execution.arrow.enabled\")\n",
        "print(test)\n",
        "\n",
        "test123=spark.conf.get(\"spark.sql.execution.arrow.pyspark.fallback.enabled\")\n",
        "print(test123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c9c2c3f",
      "metadata": {
        "id": "1c9c2c3f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}